<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Machine Learning | CrowdChat Engineering]]></title>
  <link href="http://crowdchat.github.io/blog/categories/machine-learning/atom.xml" rel="self"/>
  <link href="http://crowdchat.github.io/"/>
  <updated>2014-04-17T19:11:38-07:00</updated>
  <id>http://crowdchat.github.io/</id>
  <author>
    <name><![CDATA[CrowdChat Engineering]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Identifying Real Humans on Twitter]]></title>
    <link href="http://crowdchat.github.io/blog/2013/11/06/identifying-real-humans-on-twitter/"/>
    <updated>2013-11-06T16:58:00-08:00</updated>
    <id>http://crowdchat.github.io/blog/2013/11/06/identifying-real-humans-on-twitter</id>
    <content type="html"><![CDATA[<p>In CrowdChat platform, we have classified over 66M Twitter accounts and counting. The important precursor
step: Finding out real-humans among those millions of accounts. This may appear as seemingly intuitive task for any average person, but is not so for the machines. This post descirbes how we approached the problem. The reader should refer further for the following concepts, but we will try to introduce them as briefly as possible.</p>

<!-- more -->


<p>The of problem of identifying, if a twitter account belongs to real-human or not can be translated to the problem of identifying if their self-described bio belongs to a language class H.</p>

<p>Lets assume for now, H is language class of all self-described bios that sound like written by Humans.
And B is the language class of all bios that are written by Bots/Organization Accounts/Non-Humans.</p>

<p>A given tweet (in English) is composed of set of character n-grams.</p>

<h1>EM Algorithm</h1>

<p>Let’s recall the naive Bayes algorithm: given a tweet (a set of character n-grams), we estimate its language to be the language L that maximizes
<code>
P(language=L|ngrams)∝P(ngrams|language=L)P(language=L)
Thus, we need to estimate P(ngram|language=L) and P(language=L).
</code>
This would be easy if we knew the language of each tweet, since we could estimate</p>

<p>```
P(xyz|language=English) as #(number of times “xyz” is a trigram in the English tweets) / #(total trigrams in the English tweets)
P(language=English) as the proportion of English tweets.</p>

<p>```</p>

<p>Or, it would also be easy if we knew the n-gram probabilities for each language, since we could use Bayes’ theorem to compute the language probabilities for each tweet, and then take a weighted variant of the previous paragraph.</p>
]]></content>
  </entry>
  
</feed>
